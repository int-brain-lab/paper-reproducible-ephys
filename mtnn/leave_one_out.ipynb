{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "from mtnn import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.load('mtnn_data/train/feature.npy')\n",
    "output = np.load('mtnn_data/train/output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_order = feature[:,0,0]\n",
    "feature = feature[:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = np.unique(neuron_order)\n",
    "n_neurons = neurons.shape[0]\n",
    "print('number of neurons: {}'.format(n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN_SIZE = 16\n",
    "# INPUT_SIZE_DYNAMIC = feature.shape[-1]-static_idx.shape[0]\n",
    "# INPUT_SIZE_STATIC = static_idx.shape[0]\n",
    "# print(INPUT_SIZE_DYNAMIC, INPUT_SIZE_STATIC)\n",
    "\n",
    "INPUT_SIZE_DYNAMIC = feature.shape[-1]-static_idx.shape[0]\n",
    "INPUT_SIZE_STATIC = static_idx.shape[0]\n",
    "print(INPUT_SIZE_STATIC, INPUT_SIZE_DYNAMIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN_SIZE_STATIC = 16\n",
    "# HIDDEN_SIZE_DYNAMIC = 16\n",
    "# n_layers = 2\n",
    "\n",
    "# HIDDEN_SIZE_STATIC = 32\n",
    "# HIDDEN_SIZE_DYNAMIC = 32\n",
    "# n_layers = 2\n",
    "\n",
    "HIDDEN_SIZE_STATIC = 64\n",
    "HIDDEN_SIZE_DYNAMIC = 64\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, key in notebook.tqdm(enumerate(cov_idx_dict.keys())):\n",
    "    if key not in ['paw speed', 'nose speed', 'pupil diameter', \n",
    "                   'motion energy', 'stimuli', 'go cue', 'first movement']:\n",
    "        continue\n",
    "        \n",
    "    print(f'processing {key}')\n",
    "\n",
    "    # prev: hidden_size = 16, n_layers=2, batch_size=256, random_sliding=1~2*max\n",
    "    model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                            input_size_static=INPUT_SIZE_STATIC, \n",
    "                            input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                            static_bias=False, dynamic_bias=True, \n",
    "                            hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "                            hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "    remove_cov = None\n",
    "    only_keep_cov = key\n",
    "    # -17.1\n",
    "    best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "                                                     'mtnn_data/train/feature.npy', \n",
    "                                                     'mtnn_data/train/output.npy', \n",
    "                                                     'mtnn_data/validation/feature.npy', \n",
    "                                                     'mtnn_data/validation/output.npy',\n",
    "                                                     batch_size=256, n_epochs=100, lr=0.03,\n",
    "                                                     weight_decay=1e-4, bias_weight_decay=1e-4, #TRY HIGHER PENALTY\n",
    "                                                     remove_cov=remove_cov, \n",
    "                                                     only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                         input_size_static=INPUT_SIZE_STATIC, \n",
    "#                         input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                         static_bias=False, dynamic_bias=True, \n",
    "#                         hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "#                         hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.1)\n",
    "# remove_cov = ['all']\n",
    "# only_keep_cov = None\n",
    "# # -17.1\n",
    "# best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "#                                                  'mtnn_data/train/feature.npy', \n",
    "#                                                  'mtnn_data/train/output.npy', \n",
    "#                                                  'mtnn_data/validation/feature.npy', \n",
    "#                                                  'mtnn_data/validation/output.npy',\n",
    "#                                                  batch_size=512, n_epochs=100, lr=0.01,\n",
    "#                                                  weight_decay=5e-4, bias_weight_decay=3e0, #TRY HIGHER PENALTY\n",
    "#                                                  remove_cov=remove_cov, \n",
    "#                                                  only_keep_cov=only_keep_cov,\n",
    "#                                                  model_name_suffix='dynamic_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                        input_size_static=INPUT_SIZE_STATIC, \n",
    "                        input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                        static_bias=True, dynamic_bias=False, \n",
    "                        hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "                        hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "remove_cov = ['all']\n",
    "only_keep_cov = None\n",
    "# -17.1\n",
    "best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "                                                 'mtnn_data/train/feature.npy', \n",
    "                                                 'mtnn_data/train/output.npy', \n",
    "                                                 'mtnn_data/validation/feature.npy', \n",
    "                                                 'mtnn_data/validation/output.npy',\n",
    "                                                 batch_size=512, n_epochs=100, lr=0.03,\n",
    "                                                 weight_decay=1e-4, bias_weight_decay=1e-4, #TRY HIGHER PENALTY\n",
    "                                                 remove_cov=remove_cov, \n",
    "                                                 only_keep_cov=only_keep_cov,\n",
    "                                                 model_name_suffix='static_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                         input_size_static=INPUT_SIZE_STATIC, \n",
    "#                         input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                         static_bias=True, dynamic_bias=True, \n",
    "#                         hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "#                         hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "# remove_cov = None\n",
    "# only_keep_cov = None\n",
    "# # -16.09\n",
    "# best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "#                                                  'mtnn_data/train/feature.npy', \n",
    "#                                                  'mtnn_data/train/output.npy', \n",
    "#                                                  'mtnn_data/validation/feature.npy', \n",
    "#                                                  'mtnn_data/validation/output.npy',\n",
    "#                                                  batch_size=512, n_epochs=100, lr=0.01,\n",
    "#                                                  weight_decay=1e-5, bias_weight_decay=1e-5, #TRY HIGHER PENALTY\n",
    "#                                                  remove_cov=remove_cov, \n",
    "#                                                  only_keep_cov=only_keep_cov)\n",
    "\n",
    "model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                        input_size_static=INPUT_SIZE_STATIC, \n",
    "                        input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                        static_bias=True, dynamic_bias=True, \n",
    "                        hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "                        hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "remove_cov = None\n",
    "only_keep_cov = None\n",
    "# -16.15\n",
    "best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "                                                 'mtnn_data/train/feature.npy', \n",
    "                                                 'mtnn_data/train/output.npy', \n",
    "                                                 'mtnn_data/validation/feature.npy', \n",
    "                                                 'mtnn_data/validation/output.npy',\n",
    "                                                 batch_size=256, n_epochs=100, lr=0.03,\n",
    "                                                 weight_decay=1e-4, bias_weight_decay=1e-4, #TRY HIGHER PENALTY\n",
    "                                                 remove_cov=remove_cov, \n",
    "                                                 only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, key in enumerate(grouped_cov_idx_dict.keys()):\n",
    "#     print(f'processing {key}')\n",
    "    \n",
    "# #     model = initialize_mtnn(n_neurons=n_neurons, \n",
    "# #                             input_size_static=INPUT_SIZE_STATIC, \n",
    "# #                             input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "# #                             output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "# #                             hidden_dim_dynamic=HIDDEN_SIZE, n_layers=2)\n",
    "\n",
    "#     model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                             input_size_static=INPUT_SIZE_STATIC, \n",
    "#                             input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                             output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "#                             hidden_dim_dynamic=HIDDEN_SIZE, n_layers=2)\n",
    "\n",
    "#     remove_cov = grouped_cov_idx_dict[key]\n",
    "#     only_keep_cov = None\n",
    "    \n",
    "#     best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "#                                                      'mtnn_data/train/feature.npy', \n",
    "#                                                      'mtnn_data/train/output.npy', \n",
    "#                                                      'mtnn_data/validation/feature.npy', \n",
    "#                                                      'mtnn_data/validation/output.npy',\n",
    "#                                                      batch_size=1024, n_epochs=150, lr=0.01, \n",
    "#                                                      remove_cov=remove_cov,\n",
    "#                                                      only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(cov_idx_dict.keys()):\n",
    "    if i in [0,10,11,12,13,14,15,16,17]:\n",
    "        print(f'processing {key}')\n",
    "\n",
    "    #     model = initialize_mtnn(n_neurons=n_neurons, \n",
    "    #                             input_size_static=INPUT_SIZE_STATIC, \n",
    "    #                             input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "    #                             output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "    #                             hidden_dim_dynamic=HIDDEN_SIZE, n_layers=2)\n",
    "\n",
    "        model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                                input_size_static=INPUT_SIZE_STATIC, \n",
    "                                input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                                output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "                                hidden_dim_dynamic=HIDDEN_SIZE, n_layers=1)\n",
    "\n",
    "        remove_cov = (key,)\n",
    "        only_keep_cov = None\n",
    "\n",
    "        best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "                                                         'mtnn_data/train/feature.npy', \n",
    "                                                         'mtnn_data/train/output.npy', \n",
    "                                                         'mtnn_data/validation/feature.npy', \n",
    "                                                         'mtnn_data/validation/output.npy',\n",
    "                                                         batch_size=512, n_epochs=96, lr=0.03, \n",
    "                                                         remove_cov=remove_cov,\n",
    "                                                         only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds, test_loss = run_eval(model,'mtnn_data/test/feature.npy',\n",
    "                            'mtnn_data/test/output.npy', remove_cov=remove_cov)\n",
    "print(f'test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_shape = np.load('mtnn_data/test/shape.npy')\n",
    "obs = np.load('mtnn_data/test/output.npy')\n",
    "test_feature = np.load('mtnn_data/test/feature.npy')\n",
    "neu_list = np.load('mtnn_data/clusters.npy', allow_pickle=True)\n",
    "sess_list = np.load('mtnn_data/session_info.npy', allow_pickle=True)\n",
    "trial_list = np.load('mtnn_data/test/trials.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "obs_list = []\n",
    "feature_list = []\n",
    "idx = 0\n",
    "for sh in preds_shape:\n",
    "    n = sh[0]*sh[1]\n",
    "    pred_list.append(preds[idx:idx+n].reshape(sh[:-1]))\n",
    "    obs_list.append(obs[idx:idx+n].reshape(sh[:-1]))\n",
    "    feature_list.append(test_feature[idx:idx+n].reshape(sh))\n",
    "    idx += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sess = 1\n",
    "# for i in range(10):\n",
    "#     plt.figure(figsize=(10,4))\n",
    "#     plt.plot(obs_list[sess][i].mean(0), color='k')\n",
    "#     plt.plot(pred_list[sess][i].mean(0), color='r')\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.imshow(obs_list[sess][i], aspect='auto')\n",
    "#     plt.show()\n",
    "#     plt.figure()\n",
    "#     plt.imshow(pred_list[sess][i], aspect='auto')\n",
    "#     plt.show()\n",
    "#     print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_figure_9(feature_list, pred_list, obs_list, \n",
    "                neu_list, sess_list, trial_list, which_sess=None, savefig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift3D(tensor, shifts: torch.LongTensor):\n",
    "    # assumes 3D tensor\n",
    "    n_batches, n_rows, n_cols = tensor.shape\n",
    "\n",
    "    arange1 = torch.arange(n_rows).view((1,n_rows,1)).repeat((n_batches,1,n_cols))\n",
    "    arange2 = (arange1 - shifts) % n_rows\n",
    "    return torch.gather(tensor, 1, arange2)\n",
    "\n",
    "def shift2D(mat, shifts: torch.LongTensor):\n",
    "    # assumes 2D matrix\n",
    "    n_batches, n_rows = mat.shape\n",
    "\n",
    "    arange1 = torch.arange(n_rows).view((1,n_rows)).repeat((n_batches,1))\n",
    "    arange2 = (arange1 - shifts) % n_rows\n",
    "    arange2 = arange2.cuda()\n",
    "    shifted = torch.gather(mat, 1, arange2)\n",
    "    \n",
    "    del arange2\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "def random_flip_pad_shift(dynamic_f):\n",
    "    \n",
    "    # flip\n",
    "    flip = False #np.random.choice([0,1], size=1).astype(bool)[0]\n",
    "    flipped = torch.flip(dynamic_f, [1]) if flip else dynamic_f\n",
    "    \n",
    "    pre_padding, post_padding = np.random.randint(dynamic_f.shape[1]+dynamic_f.shape[1]//2,\n",
    "                                                  dynamic_f.shape[1]*4,\n",
    "                                                  size=2)\n",
    "    # TODO: use torch.nn.functional.pad\n",
    "    pre = torch.randn((dynamic_f.shape[0], pre_padding, dynamic_f.shape[-1]))\n",
    "    post = torch.randn((dynamic_f.shape[0], post_padding, dynamic_f.shape[-1]))\n",
    "    padded = torch.cat((pre, dynamic_f, post), dim=1)\n",
    "    #padded = pad(flipped, (0,0,pre_padding,post_padding))\n",
    "    \n",
    "    # random shifting\n",
    "    shifts = torch.randint(-(pre_padding-dynamic_f.shape[1]),\n",
    "                           (post_padding-dynamic_f.shape[1]),\n",
    "                           size=[padded.shape[0],1,1])\n",
    "    rolled = shift3D(padded, shifts)\n",
    "    \n",
    "    return rolled, flip, pre_padding, post_padding, shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_f = torch.zeros(3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dynamic_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled, flip, pre_padding, post_padding, shifts = random_flip_pad_shift(dynamic_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv-updated",
   "language": "python",
   "name": "iblenv-updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
