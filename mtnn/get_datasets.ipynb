{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import brainbox.io.one as bbone\n",
    "from reproducible_ephys_functions import query\n",
    "from tqdm import notebook\n",
    "import brainbox as bb\n",
    "from ibllib.io import spikeglx\n",
    "import brainbox.behavior.wheel as wh\n",
    "from brainbox import singlecell\n",
    "from brainbox.metrics.single_units import spike_sorting_metrics\n",
    "from one.api import ONE\n",
    "import alf\n",
    "\n",
    "from ibllib.qc.camera import CameraQC\n",
    "import os\n",
    "from scipy.stats import zscore\n",
    "from collections import Counter\n",
    "\n",
    "from utils import *\n",
    "\n",
    "one = ONE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtnn_criteria = check_mtnn_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all rs trajectories\n",
    "trajs = query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for eid in mtnn_criteria.keys():\n",
    "    print(eid)\n",
    "    print(mtnn_criteria[eid])\n",
    "    for traj in trajs:\n",
    "        if traj['session']['id'] == eid:\n",
    "            print(traj)\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'56b57c38-2699-4091-90a8-aba35103155e': 0}\n"
     ]
    }
   ],
   "source": [
    "mtnn_eids = get_mtnn_eids()\n",
    "print(mtnn_eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Charles's behavioral model\n",
    "# run_exp_prevAction(mtnn_eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0e6c55bc-d2af-45e1-b960-87b7d203dc89', 'probe_insertion': 'ce397420-3cd2-4a55-8fd1-5e28321981f4', 'x': -2243.0, 'y': -2000.0, 'z': -169.0, 'depth': 4000.0, 'theta': 15.0, 'phi': 180.0, 'roll': 0.0, 'provenance': 'Planned', 'session': {'subject': 'SWC_054', 'start_time': '2020-10-05T19:15:05.974514', 'number': 1, 'lab': 'mrsicflogellab', 'id': '56b57c38-2699-4091-90a8-aba35103155e', 'task_protocol': '_iblrig_tasks_ephysChoiceWorld6.4.2'}, 'probe_name': 'probe01', 'coordinate_system': None, 'datetime': '2020-12-05T15:34:21.905537', 'json': None}]\n"
     ]
    }
   ],
   "source": [
    "traj = get_traj(mtnn_eids)\n",
    "print(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ts_directory = os.path.join('.', \"new_timestamps\")\n",
    "# if not os.path.exists(ts_directory):\n",
    "#     os.makedirs(ts_directory)\n",
    "# for i in notebook.tqdm(range(len(traj))):\n",
    "#     eid = traj[i]['session']['id']\n",
    "#     get_new_timestamps(eid, 'left', ts_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec1a0d3491949b090c732b243a04340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2022-02-28 02:34:15.806 WARNING  [one.py:515] Deprecation warning: brainbox.io.one.load_spike_sorting will be removed in future versions.Use brainbox.io.one.SpikeSortingLoader instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing SWC_054: 56b57c38-2699-4091-90a8-aba35103155e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2022-02-28 02:34:16.718 WARNING  [one.py:462] Deprecation warning: brainbox.io.one.load_spike_sorting will be removed in future versions.Use brainbox.io.one.SpikeSortingLoader instead\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spikes retrieved\n",
      "loading motion energy and dlc\n",
      "motion energy + dlc retrieved\n",
      "loading pLeft\n",
      "trial info retrieved\n",
      "passive data loaded\n",
      "number of trials found: 697 (active: 517, passive: 180)\n",
      "getting lick times\n",
      "getting paw speed\n",
      "getting nose speed\n",
      "getting pupil diameter\n",
      "getting wheel velocity\n",
      "all brain region counts:  Counter({'PPC': 55, 'PO': 49, 'LP': 49, 'CA1': 12, 'DG': 3})\n",
      "good cluster id:  [109 120 166 115 165 162 364 309 122 289]\n",
      "selected brain region counts:  Counter({'PO': 7, 'LP': 3})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9df3156b6ed4918b13a9a264dcb1138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3ef4ed089c4fb2a80c6eb207841afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b24cfae9a6c42c3ac78b860c69a0e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "output_list = []\n",
    "trial_length_array_list = []\n",
    "cluster_number_list = []\n",
    "session_list = []\n",
    "nan_trials = []\n",
    "session_count = {'mainenlab': 0, 'churchlandlab': 0, ('hoferlab', 'mrsicflogellab'): 0, 'danlab': 0}\n",
    "for i in notebook.tqdm(range(len(traj))):\n",
    "    feature, output, trial_length_array, cluster_numbers, nan_idx, success = featurize(i, \n",
    "                                                                                       traj[i], \n",
    "                                                                                       one, \n",
    "                                                                                       session_count)\n",
    "    if not success:\n",
    "        print('not successful')\n",
    "        continue\n",
    "    else:\n",
    "        print('successful')\n",
    "    feature_list.append(feature)\n",
    "    output_list.append(output)\n",
    "    trial_length_array_list.append(trial_length_array)\n",
    "    cluster_number_list.append(cluster_numbers)\n",
    "    session_list.append(traj[i])\n",
    "    nan_trials.append(nan_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(feature_list)):\n",
    "    print(feature_list[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output_list)):\n",
    "    print(output_list[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_list = []\n",
    "for i in range(len(output_list)):\n",
    "    mean_fr = output_list[i].mean(2).mean(0)\n",
    "    top_k = mean_fr.argsort()[::-1][:250]\n",
    "    topk_list.append(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_feature_list = []\n",
    "for i in range(len(feature_list)):\n",
    "    top_k = topk_list[i]\n",
    "    feature = feature_list[i][:,top_k]\n",
    "    for k in range(10):\n",
    "        feature[k,:,:,0] = 10*i + k\n",
    "    truncated_feature_list.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_feature = np.asarray(truncated_feature_list)\n",
    "print(truncated_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('truncated_feature_original.npy', truncated_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen_list = []\n",
    "for i in range(len(trial_length_array_list)):\n",
    "    top_k = topk_list[i]\n",
    "    seqlen_list.append(trial_length_array_list[i][top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen_array = np.asarray(seqlen_list)\n",
    "print(seqlen_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('seqlen.npy', seqlen_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize truncated_feature: dlc features + xyz location\n",
    "# first normalize xyz\n",
    "x_max = truncated_feature[:,:,:,:,xyz_offset].max()\n",
    "x_min = truncated_feature[:,:,:,:,xyz_offset].min()\n",
    "y_max = truncated_feature[:,:,:,:,xyz_offset+1].max()\n",
    "y_min = truncated_feature[:,:,:,:,xyz_offset+1].min()\n",
    "z_max = truncated_feature[:,:,:,:,xyz_offset+2].max()\n",
    "z_min = truncated_feature[:,:,:,:,xyz_offset+2].min()\n",
    "\n",
    "truncated_feature[:,:,:,:,xyz_offset] = 0.1 + 0.9*(truncated_feature[:,:,:,:,xyz_offset] - x_min) / (x_max - x_min)\n",
    "truncated_feature[:,:,:,:,xyz_offset+1] = 0.1 + 0.9*(truncated_feature[:,:,:,:,xyz_offset+1] - y_min) / (y_max - y_min)\n",
    "truncated_feature[:,:,:,:,xyz_offset+2] = 0.1 + 0.9*(truncated_feature[:,:,:,:,xyz_offset+2] - z_min) / (z_max - z_min)\n",
    "\n",
    "# next normalize dlc features\n",
    "for i in range(stimOnOff_offset - left_dlc_offset):\n",
    "    idx = left_dlc_offset+i\n",
    "    \n",
    "    feature_min = truncated_feature[:,:,:,:,idx].min()\n",
    "    feature_max = truncated_feature[:,:,:,:,idx].max()\n",
    "    \n",
    "    truncated_feature[:,:,:,:,idx] = -1 + 2*(truncated_feature[:,:,:,:,idx] - feature_min) / (feature_max - feature_min)\n",
    "    \n",
    "# next normalize wheel\n",
    "wheel_min = truncated_feature[:,:,:,:,wheel_offset].min()\n",
    "wheel_max = truncated_feature[:,:,:,:,wheel_offset].max()\n",
    "\n",
    "truncated_feature[:,:,:,:,wheel_offset] = -1 + 2*(truncated_feature[:,:,:,:,wheel_offset] - wheel_min) / (wheel_max - wheel_min)\n",
    "\n",
    "\n",
    "# next normalize lick\n",
    "lick_min = truncated_feature[:,:,:,:,lick_offset].min()\n",
    "lick_max = truncated_feature[:,:,:,:,lick_offset].max()\n",
    "\n",
    "truncated_feature[:,:,:,:,lick_offset] = (truncated_feature[:,:,:,:,lick_offset] - lick_min) / (lick_max - lick_min)\n",
    "\n",
    "# next normalize max_ptp\n",
    "max_ptp_min = truncated_feature[:,:,:,:,max_ptp_offset].min()\n",
    "max_ptp_max = truncated_feature[:,:,:,:,max_ptp_offset].max()\n",
    "\n",
    "truncated_feature[:,:,:,:,max_ptp_offset] = 0.1 + 0.9*(truncated_feature[:,:,:,:,max_ptp_offset] - max_ptp_min) / (max_ptp_max - max_ptp_min)\n",
    "\n",
    "# next normalize wf_width\n",
    "wf_width_min = truncated_feature[:,:,:,:,wf_width_offset].min()\n",
    "wf_width_max = truncated_feature[:,:,:,:,wf_width_offset].max()\n",
    "\n",
    "truncated_feature[:,:,:,:,wf_width_offset] = 0.1 + 0.9*(truncated_feature[:,:,:,:,wf_width_offset] - wf_width_min) / (wf_width_max - wf_width_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('truncated_feature_normalized.npy', truncated_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_target_list = []\n",
    "for i in range(len(output_list)):\n",
    "    top_k = topk_list[i]\n",
    "    output = output_list[i][:,top_k]\n",
    "    truncated_target_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_target = np.asarray(truncated_target_list)\n",
    "print(truncated_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('truncated_output.npy', truncated_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv-updated",
   "language": "python",
   "name": "iblenv-updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
