{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from mtnn import *\n",
    "from figure9 import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.load('mtnn_data/train/feature.npy')\n",
    "output = np.load('mtnn_data/train/output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_order = feature[:,0,0]\n",
    "feature = feature[:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = np.unique(neuron_order)\n",
    "n_neurons = neurons.shape[0]\n",
    "print('number of neurons: {}'.format(n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE_DYNAMIC = feature.shape[-1]-static_idx.shape[0]\n",
    "INPUT_SIZE_STATIC = static_idx.shape[0]\n",
    "print(INPUT_SIZE_STATIC, INPUT_SIZE_DYNAMIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN_SIZE_STATIC = 16\n",
    "# HIDDEN_SIZE_DYNAMIC = 16\n",
    "# n_layers = 2\n",
    "\n",
    "HIDDEN_SIZE_STATIC = 64\n",
    "HIDDEN_SIZE_DYNAMIC = 64\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                         input_size_static=INPUT_SIZE_STATIC, \n",
    "#                         input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                         static_bias=False, dynamic_bias=True, \n",
    "#                         hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "#                         hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "# remove_cov = ['all']\n",
    "# only_keep_cov = None\n",
    "# # -16.15\n",
    "# best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "#                                                  'mtnn_data/train/feature.npy', \n",
    "#                                                  'mtnn_data/train/output.npy', \n",
    "#                                                  'mtnn_data/validation/feature.npy', \n",
    "#                                                  'mtnn_data/validation/output.npy',\n",
    "#                                                  batch_size=1024, n_epochs=100, lr=0.03,\n",
    "#                                                  weight_decay=1e-4, bias_weight_decay=1e-4, #TRY HIGHER PENALTY\n",
    "#                                                  remove_cov=remove_cov, \n",
    "#                                                  only_keep_cov=only_keep_cov,\n",
    "#                                                  model_name_suffix='dynamic_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, key in notebook.tqdm(enumerate(cov_idx_dict.keys())):\n",
    "    if key in ['go cue', 'first movement', 'choice', 'reward', 'wheel velocity', 'mouse prior',\n",
    "               'last mouse prior', 'lick', 'decision strategy (GLM-HMM)',\n",
    "               'brain region', 'noise', 'all']:\n",
    "        continue\n",
    "        \n",
    "    print(f'processing {key}')\n",
    "\n",
    "    # prev: hidden_size = 16, n_layers=2, batch_size=256, random_sliding=1~2*max\n",
    "    model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                            input_size_static=INPUT_SIZE_STATIC, \n",
    "                            input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                            static_bias=True, dynamic_bias=True, \n",
    "                            hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "                            hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.5)\n",
    "    remove_cov = [key]\n",
    "    only_keep_cov = None\n",
    "    # -17.1\n",
    "    best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "                                                     'mtnn_data/train/feature.npy', \n",
    "                                                     'mtnn_data/train/output.npy', \n",
    "                                                     'mtnn_data/validation/feature.npy', \n",
    "                                                     'mtnn_data/validation/output.npy',\n",
    "                                                     batch_size=512, n_epochs=100, lr=0.03,\n",
    "                                                     weight_decay=1e-4, bias_weight_decay=1e-4, #TRY HIGHER PENALTY\n",
    "                                                     remove_cov=remove_cov, \n",
    "                                                     only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(feature[:,:,noise_offset].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # prev: hidden_size = 16, n_layers=2, batch_size=256, random_sliding=1~2*max\n",
    "# model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                         input_size_static=INPUT_SIZE_STATIC, \n",
    "#                         input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                         output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "#                         hidden_dim_dynamic=HIDDEN_SIZE, n_layers=1)\n",
    "# remove_cov = None\n",
    "# only_keep_cov = None\n",
    "# best_epoch, loss_list, val_loss_list = run_train(model, \n",
    "#                                                  'mtnn_data/train/feature.npy', \n",
    "#                                                  'mtnn_data/train/output.npy', \n",
    "#                                                  'mtnn_data/validation/feature.npy', \n",
    "#                                                  'mtnn_data/validation/output.npy',\n",
    "#                                                  batch_size=512, n_epochs=100, lr=0.03, \n",
    "#                                                  remove_cov=remove_cov, \n",
    "#                                                  only_keep_cov=only_keep_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(loss_list[1:], color='k')\n",
    "# plt.plot(val_loss_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_shape = np.load('mtnn_data/test/shape.npy')\n",
    "# obs = np.load('mtnn_data/test/output.npy')\n",
    "# test_feature = np.load('mtnn_data/test/feature.npy')\n",
    "# neu_list = np.load('mtnn_data/clusters.npy', allow_pickle=True)\n",
    "# sess_list = np.load('mtnn_data/session_info.npy', allow_pickle=True)\n",
    "# trial_list = np.load('mtnn_data/test/trials.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cov_pair_list = [(None,None), (('all',),None), (None, 'noise')]\n",
    "# scores = dict()\n",
    "# for cov_pair in cov_pair_list:\n",
    "#     remove_cov = cov_pair[0]\n",
    "#     only_keep_cov = cov_pair[1]\n",
    "    \n",
    "#     model = initialize_mtnn(n_neurons=n_neurons, \n",
    "#                             input_size_static=INPUT_SIZE_STATIC, \n",
    "#                             input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "#                             output_size=1, hidden_dim_static=HIDDEN_SIZE, \n",
    "#                             hidden_dim_dynamic=HIDDEN_SIZE, n_layers=1)\n",
    "\n",
    "#     print('loading... '+f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt')\n",
    "#     model.load_state_dict(torch.load(f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt'))\n",
    "    \n",
    "#     preds, test_loss = run_eval(model,'mtnn_data/test/feature.npy',\n",
    "#                                 'mtnn_data/test/output.npy', \n",
    "#                                 remove_cov=remove_cov, \n",
    "#                                 only_keep_cov=only_keep_cov)\n",
    "#     print(f'test loss: {test_loss}')\n",
    "    \n",
    "#     pred_list = []\n",
    "#     obs_list = []\n",
    "#     feature_list = []\n",
    "#     idx = 0\n",
    "#     for sh in preds_shape:\n",
    "#         n = sh[0]*sh[1]\n",
    "#         pred_list.append(preds[idx:idx+n].reshape(sh[:-1]))\n",
    "#         obs_list.append(obs[idx:idx+n].reshape(sh[:-1]))\n",
    "#         feature_list.append(test_feature[idx:idx+n].reshape(sh))\n",
    "#         idx += n\n",
    "    \n",
    "#     for sess in range(len(sess_list)):\n",
    "#         score = compute_score(obs_list[sess], \n",
    "#                               pred_list[sess], \n",
    "#                               metric='r2', \n",
    "#                               use_psth=False)['r2']\n",
    "#         scores[(cov_pair,sess)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for sess in range(len(sess_list)):\n",
    "#     n = obs_list[sess].shape[0]\n",
    "#     plt.figure()\n",
    "#     plt.scatter(np.ones(n), scores[(None,None),sess])\n",
    "#     plt.scatter(np.ones(n)*2, scores[(('all',),None),sess])\n",
    "#     plt.scatter(np.ones(n)*3, scores[(None,'noise'),sess])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate_figure_9(feature_list, pred_list, obs_list, \n",
    "#                 neu_list, sess_list, trial_list, which_sess=[1], savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_bias = True\n",
    "cov = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_mtnn(n_neurons=n_neurons, \n",
    "                        input_size_static=INPUT_SIZE_STATIC, \n",
    "                        input_size_dynamic=INPUT_SIZE_DYNAMIC,\n",
    "                        static_bias=static_bias, dynamic_bias=True, \n",
    "                        hidden_dim_static=HIDDEN_SIZE_STATIC, \n",
    "                        hidden_dim_dynamic=HIDDEN_SIZE_DYNAMIC, n_layers=n_layers, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cov = None #['all']\n",
    "only_keep_cov = cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading... '+f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt')\n",
    "model.load_state_dict(torch.load(f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt'))\n",
    "\n",
    "# print('loading... '+f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}.pt')\n",
    "# model.load_state_dict(torch.load(f'trained_models/state_dict_rem={remove_cov}_keep={only_keep_cov}_dynamic_bias.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'test'\n",
    "preds, loss = run_eval(model,f'mtnn_data/{data_dir}/feature.npy',\n",
    "                            f'mtnn_data/{data_dir}/output.npy', \n",
    "                            remove_cov=remove_cov, only_keep_cov=only_keep_cov)\n",
    "print(f'{data_dir} loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_shape = np.load(f'mtnn_data/{data_dir}/shape.npy')\n",
    "obs = np.load(f'mtnn_data/{data_dir}/output.npy')\n",
    "test_feature = np.load(f'mtnn_data/{data_dir}/feature.npy')\n",
    "neu_list = np.load('mtnn_data/clusters.npy', allow_pickle=True)\n",
    "sess_list = np.load('mtnn_data/session_info.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "obs_list = []\n",
    "feature_list = []\n",
    "idx = 0\n",
    "for sh in preds_shape:\n",
    "    n = sh[0]*sh[1]\n",
    "    pred_list.append(preds[idx:idx+n].reshape(sh[:-1]))\n",
    "    obs_list.append(obs[idx:idx+n].reshape(sh[:-1]))\n",
    "    feature_list.append(test_feature[idx:idx+n].reshape(sh))\n",
    "    idx += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {'n_neurons': n_neurons,\n",
    "                'input_size_static': INPUT_SIZE_STATIC,\n",
    "                'input_size_dynamic': INPUT_SIZE_DYNAMIC,\n",
    "                'hidden_size_static': HIDDEN_SIZE_STATIC,\n",
    "                'hidden_size_dynamic': HIDDEN_SIZE_DYNAMIC,\n",
    "                'static_bias': static_bias,\n",
    "                'dynamic_bias': True,\n",
    "                'n_layers': n_layers}\n",
    "\n",
    "model_config2 = {'n_neurons': n_neurons,\n",
    "                'input_size_static': INPUT_SIZE_STATIC,\n",
    "                'input_size_dynamic': INPUT_SIZE_DYNAMIC,\n",
    "                'hidden_size_static': 64,\n",
    "                'hidden_size_dynamic': 64,\n",
    "                'static_bias': static_bias,\n",
    "                'dynamic_bias': True,\n",
    "                'n_layers': n_layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'test'\n",
    "preds_shape = np.load(f'mtnn_data/{data_dir}/shape.npy')\n",
    "obs = np.load(f'mtnn_data/{data_dir}/output.npy')\n",
    "test_feature = np.load(f'mtnn_data/{data_dir}/feature.npy')\n",
    "trial_list = np.load(f'mtnn_data/{data_dir}/trials.npy', allow_pickle=True)\n",
    "\n",
    "obs_list = []\n",
    "feature_list = []\n",
    "idx = 0\n",
    "for sh in preds_shape:\n",
    "    n = sh[0]*sh[1]\n",
    "    obs_list.append(obs[idx:idx+n].reshape(sh[:-1]))\n",
    "    feature_list.append(test_feature[idx:idx+n].reshape(sh))\n",
    "    idx += n\n",
    "baseline_score = load_test_model(model_config, None, cov, \n",
    "                                 obs_list, preds_shape, use_psth=False, \n",
    "                                 data_dir=data_dir, model_name_suffix=None)\n",
    "# baseline_score2 = load_test_model(model_config2, None, cov, \n",
    "#                                  obs_list, preds_shape, use_psth=False, \n",
    "#                                  data_dir=data_dir, model_name_suffix='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "plt.scatter(np.ones_like(baseline_score)+np.random.normal(size=baseline_score.shape[0])/10, \n",
    "            baseline_score, color='k', alpha=0.2)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(0,2)\n",
    "plt.axhline(np.median(baseline_score), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "plt.scatter(np.ones_like(baseline_score)+np.random.normal(size=baseline_score.shape[0])/10, \n",
    "            baseline_score, color='k', alpha=0.2)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(0,2)\n",
    "plt.axhline(np.median(baseline_score), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,12))\n",
    "# plt.scatter(np.ones_like(baseline_score)+np.random.normal(size=baseline_score.shape[0])/10, \n",
    "#             baseline_score2, color='k', alpha=0.2)\n",
    "# plt.ylim(-0.2,0.8)\n",
    "# plt.xlim(0,2)\n",
    "# plt.axhline(np.median(baseline_score2), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "plt.scatter(np.ones_like(baseline_score)+np.random.normal(size=baseline_score.shape[0])/10, \n",
    "            baseline_score, color='k', alpha=0.2)\n",
    "plt.ylim(-0.2,0.8)\n",
    "plt.xlim(0,2)\n",
    "plt.axhline(np.median(baseline_score), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_scores = np.load('glm_scores.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(baseline_score, glm_scores, color='k', alpha=0.4)\n",
    "plt.plot([-1,1],[-1,1], color='k')\n",
    "plt.xlim(-0.05,0.52)\n",
    "plt.ylim(-0.05,0.52)\n",
    "plt.ylabel('GLM R2')\n",
    "plt.xlabel('MTNN R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(baseline_score, glm_scores, color='k', alpha=0.4)\n",
    "plt.plot([-1,1],[-1,1], color='k')\n",
    "plt.xlim(-0.05,0.52)\n",
    "plt.ylim(-0.05,0.52)\n",
    "plt.ylabel('GLM R2')\n",
    "plt.xlabel('MTNN R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(baseline_score, baseline_score2, color='k', alpha=0.4)\n",
    "plt.plot([-1,1],[-1,1], color='k')\n",
    "plt.xlim(-0.05,0.52)\n",
    "plt.ylim(-0.05,0.52)\n",
    "plt.ylabel('(prev) MTNN R2')\n",
    "plt.xlabel('MTNN R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(baseline_score, baseline_score2, color='k', alpha=0.4)\n",
    "plt.plot([-1,1],[-1,1], color='k')\n",
    "plt.xlim(-0.05,0.52)\n",
    "plt.ylim(-0.05,0.52)\n",
    "plt.ylabel('(prev) MTNN R2')\n",
    "plt.xlabel('MTNN R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_score = reshape_flattened(baseline_score, preds_shape, trim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_score > 0.25).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, reshaped in enumerate(reshaped_score):\n",
    "    print(i)\n",
    "    idx = reshaped > 0.25\n",
    "    generate_figure_9(feature_list, pred_list, obs_list, \n",
    "                    neu_list, sess_list, trial_list, which_sess=[i], \n",
    "                      savefig=False, plot_subsample_ratio=1.0, plot_neurons = idx, subdir='good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv-updated",
   "language": "python",
   "name": "iblenv-updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
