{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from one.api import ONE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "# import brainbox.modeling.design_matrix as dm\n",
    "# import brainbox.modeling.linear as lm\n",
    "# import brainbox.modeling.utils as mut\n",
    "# import brainbox.io.one as bbone\n",
    "# from brainbox.modeling.design_matrix import convbasis\n",
    "\n",
    "from numpy.random import uniform, normal\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "# from reproducible_ephys_functions import save_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = ONE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtnn_eids = get_mtnn_eids()\n",
    "print(list(mtnn_eids.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = get_traj(mtnn_eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_path = save_data_path(figure='figure8').joinpath('mtnn_data')\n",
    "\n",
    "train_trial_ids = np.load(data_load_path.joinpath('train/trials.npy'), allow_pickle=True)\n",
    "val_trial_ids = np.load(data_load_path.joinpath('validation/trials.npy'), allow_pickle=True)\n",
    "test_trial_ids = np.load(data_load_path.joinpath('test/trials.npy'), allow_pickle=True)\n",
    "\n",
    "clusters = np.load(data_load_path.joinpath('clusters.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 0.05\n",
    "\n",
    "trialsdf_list = []\n",
    "prior_list = []\n",
    "cluster_list = []\n",
    "spk_times_list = []\n",
    "clus_list = []\n",
    "for i, eid in enumerate(mtnn_eids):\n",
    "    \n",
    "    trials = one.load_object(eid, 'trials', collection='alf')\n",
    "    \n",
    "    diff1 = trials.firstMovement_times - trials.stimOn_times\n",
    "    diff2 = trials.feedback_times - trials.firstMovement_times\n",
    "    t_select1 = np.logical_and(diff1 > 0.0, diff1 < t_before-0.1)\n",
    "    t_select2 = np.logical_and(diff2 > 0.0, diff2 < t_after-0.1)\n",
    "    keeptrials = np.logical_and(t_select1, t_select2)\n",
    "    \n",
    "    trialsdf = bbone.load_trials_df(eid,\n",
    "                                    maxlen=1.5, t_before=0.5, t_after=1.0,\n",
    "                                    wheel_binsize=binwidth, ret_abswheel=False,\n",
    "                                    ret_wheel=True, addtl_types=['firstMovement_times'],\n",
    "                                    one=one, align_event='firstMovement_times', keeptrials=keeptrials)\n",
    "    \n",
    "    trial_idx = np.concatenate([train_trial_ids[i], val_trial_ids[i], test_trial_ids[i]])\n",
    "    trial_idx = np.sort(trial_idx)\n",
    "    trialsdf = trialsdf.loc[trial_idx]\n",
    "    trialsdf_list.append(trialsdf)\n",
    "    \n",
    "    pLeft = np.load('./priors/prior_{}.npy'.format(eid))\n",
    "    prior_list.append(pLeft[trial_idx])\n",
    "    \n",
    "    cluster_list.append(clusters[i])\n",
    "    \n",
    "    traj = trajs[i]\n",
    "    probe = traj['probe_name']\n",
    "    spikes, clus, channels = bbone.load_spike_sorting_with_channel(eid, \n",
    "                                                                   one=one, \n",
    "                                                                   probe=probe, \n",
    "                                                                   spike_sorter='pykilosort')\n",
    "    spikes = spikes[probe]\n",
    "    clus = clus[probe]\n",
    "    channels = channels[probe]\n",
    "    \n",
    "    clu_idx = np.isin(spikes.clusters, clusters[i])\n",
    "    spk_times = spikes.times[clu_idx]\n",
    "    selected_clus = spikes.clusters[clu_idx]\n",
    "    \n",
    "    spk_times_list.append(spk_times)\n",
    "    clus_list.append(selected_clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_binf(t):\n",
    "    return np.ceil(t / binwidth).astype(int)\n",
    "bases = {\n",
    "    'stim': mut.raised_cosine(0.4, 5, tmp_binf),\n",
    "    'feedback': mut.raised_cosine(0.4, 5, tmp_binf),\n",
    "    'wheel': mut.raised_cosine(0.3, 3, tmp_binf),\n",
    "    'fmove': mut.raised_cosine(0.2, 3, tmp_binf),\n",
    "}\n",
    "\n",
    "def generate_design(trialsdf, prior, t_before, bases, prior_last=None,\n",
    "                    iti_prior=[-0.4, -0.1], fmove_offset=-0.4, wheel_offset=-0.4,\n",
    "                    contnorm=5., binwidth=0.05, reduce_wheel_dim=True):\n",
    "    \"\"\"\n",
    "    Generate GLM design matrix object\n",
    "    Parameters\n",
    "    ----------\n",
    "    trialsdf : pd.DataFrame\n",
    "        Trials dataframe with trial timings in absolute (since session start) time\n",
    "    prior : array-like\n",
    "        Vector containing the prior estimate or true prior for each trial. Must be same length as\n",
    "        trialsdf.\n",
    "    t_before : float\n",
    "        Time, in seconds, before stimulus onset that was used to define trial_start in trialsdf\n",
    "    bases : dict\n",
    "        Dictionary of basis functions for each regressor. Needs keys 'stim', 'feedback', 'fmove',\n",
    "        (first movement) and 'wheel'.\n",
    "    iti_prior : list, optional\n",
    "        Two element list defining bounds on which step function for ITI prior is\n",
    "        applied, by default [-0.4, -0.1]\n",
    "    contnorm : float, optional\n",
    "        Normalization factor for contrast, by default 5.\n",
    "    binwidth : float, optional\n",
    "        Size of bins to use for design matrix, in seconds, by default 0.02\n",
    "    \"\"\"\n",
    "    trialsdf['adj_contrastL'] = np.tanh(contnorm * trialsdf['contrastLeft']) / np.tanh(contnorm)\n",
    "    trialsdf['adj_contrastR'] = np.tanh(contnorm * trialsdf['contrastRight']) / np.tanh(contnorm)\n",
    "    trialsdf['prior'] = prior\n",
    "    if prior_last is None:\n",
    "        trialsdf['prior_last'] = pd.Series(np.roll(trialsdf['prior'], 1), index=trialsdf.index)\n",
    "    else:\n",
    "        trialsdf['prior_last'] = prior_last\n",
    "\n",
    "    vartypes = {'choice': 'value',\n",
    "                'response_times': 'timing',\n",
    "                'probabilityLeft': 'value',\n",
    "                'feedbackType': 'value',\n",
    "                'feedback_times': 'timing',\n",
    "                'contrastLeft': 'value',\n",
    "                'adj_contrastL': 'value',\n",
    "                'contrastRight': 'value',\n",
    "                'adj_contrastR': 'value',\n",
    "                'goCue_times': 'timing',\n",
    "                'stimOn_times': 'timing',\n",
    "                'trial_start': 'timing',\n",
    "                'trial_end': 'timing',\n",
    "                'prior': 'value',\n",
    "                'prior_last': 'value',\n",
    "                'wheel_velocity': 'continuous',\n",
    "                'firstMovement_times': 'timing'}\n",
    "\n",
    "    def stepfunc_prestim(row):\n",
    "        stepvec = np.zeros(design.binf(row.duration))\n",
    "        diff = row.stimOn_times - row.trial_start\n",
    "        stimOn_bin = design.binf(diff)\n",
    "        stepvec[0:stimOn_bin-1] = row.prior_last\n",
    "        return stepvec\n",
    "\n",
    "    def stepfunc_poststim(row):\n",
    "        zerovec = np.zeros(design.binf(row.duration))\n",
    "        currtr_start = design.binf(row.stimOn_times + 0.1)\n",
    "        currtr_end = design.binf(row.feedback_times)\n",
    "        zerovec[currtr_start:currtr_end] = row.prior_last\n",
    "        zerovec[currtr_end:] = row.prior\n",
    "        return zerovec\n",
    "\n",
    "    design = dm.DesignMatrix(trialsdf, vartypes, binwidth=binwidth)\n",
    "#     stepbounds = [design.binf(t_before + iti_prior[0]), design.binf(t_before + iti_prior[1])]\n",
    "#     print(stepbounds)\n",
    "\n",
    "    design.add_covariate_timing('stimonL', 'stimOn_times', bases['stim'],\n",
    "                                cond=lambda tr: np.isfinite(tr.contrastLeft),\n",
    "                                deltaval='adj_contrastL',\n",
    "                                desc='Kernel conditioned on L stimulus onset')\n",
    "    design.add_covariate_timing('stimonR', 'stimOn_times', bases['stim'],\n",
    "                                cond=lambda tr: np.isfinite(tr.contrastRight),\n",
    "                                deltaval='adj_contrastR',\n",
    "                                desc='Kernel conditioned on R stimulus onset')\n",
    "    design.add_covariate_timing('correct', 'feedback_times', bases['feedback'],\n",
    "                                cond=lambda tr: tr.feedbackType == 1,\n",
    "                                desc='Kernel conditioned on correct feedback')\n",
    "    design.add_covariate_timing('incorrect', 'feedback_times', bases['feedback'],\n",
    "                                cond=lambda tr: tr.feedbackType == -1,\n",
    "                                desc='Kernel conditioned on incorrect feedback')\n",
    "    design.add_covariate_timing('fmove', 'firstMovement_times', bases['fmove'],\n",
    "                                offset=fmove_offset,\n",
    "                                desc='Lead up to first movement')\n",
    "    design.add_covariate_raw('pLeft', stepfunc_prestim,\n",
    "                             desc='Step function on prior estimate')\n",
    "    design.add_covariate_raw('pLeft_tr', stepfunc_poststim,\n",
    "                             desc='Step function on post-stimulus prior')\n",
    "\n",
    "    design.add_covariate('wheel', trialsdf['wheel_velocity'], bases['wheel'], wheel_offset)\n",
    "    design.compile_design_matrix()\n",
    "\n",
    "    if reduce_wheel_dim:\n",
    "        _, s, v = np.linalg.svd(design[:, design.covar['wheel']['dmcol_idx']],\n",
    "                                full_matrices=False)\n",
    "        variances = s**2 / (s**2).sum()\n",
    "        n_keep = np.argwhere(np.cumsum(variances) >= 0.9999)[0, 0]\n",
    "        wheelcols = design[:, design.covar['wheel']['dmcol_idx']]\n",
    "        reduced = wheelcols @ v[:n_keep].T\n",
    "        bases_reduced = bases['wheel'] @ v[:n_keep].T\n",
    "        keepcols = ~np.isin(np.arange(design.dm.shape[1]), design.covar['wheel']['dmcol_idx'])\n",
    "        basedm = design[:, keepcols]\n",
    "        design.dm = np.hstack([basedm, reduced])\n",
    "        design.covar['wheel']['dmcol_idx'] = design.covar['wheel']['dmcol_idx'][:n_keep]\n",
    "        design.covar['wheel']['bases'] = bases_reduced\n",
    "\n",
    "    print('Condition of design matrix:', np.linalg.cond(design.dm))\n",
    "    return design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_list = []\n",
    "for i, trialsdf in enumerate(trialsdf_list):\n",
    "    design = generate_design(trialsdf.copy(), prior_list[i], 0.4, bases, binwidth=binwidth)\n",
    "    design_list.append(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from brainbox.modeling import linear\n",
    "from brainbox.modeling import poisson\n",
    "from brainbox.plot import peri_event_time_histogram\n",
    "\n",
    "def predict(nglm, targ_regressors=None, trials=None, retlab=False, incl_bias=True):\n",
    "    if trials is None:\n",
    "        trials = nglm.design.trialsdf.index\n",
    "    if targ_regressors is None:\n",
    "        targ_regressors = nglm.design.covar.keys()\n",
    "    dmcols = np.hstack([nglm.design.covar[r]['dmcol_idx'] for r in targ_regressors])\n",
    "    dmcols = np.sort(dmcols)\n",
    "    trlabels = nglm.design.trlabels\n",
    "    trfilter = np.isin(trlabels, trials).flatten()\n",
    "    w = nglm.coefs\n",
    "    b = nglm.intercepts\n",
    "    dm = nglm.design.dm[trfilter, :][:, dmcols]\n",
    "    if type(nglm) == poisson.PoissonGLM:\n",
    "        link = np.exp\n",
    "    elif type(nglm) == linear.LinearGLM:\n",
    "        def link(x):\n",
    "            return x\n",
    "    else:\n",
    "        raise TypeError('nglm must be poisson or linear')\n",
    "    if incl_bias:\n",
    "        pred = {cell: link(dm @ w.loc[cell][dmcols] + b.loc[cell]) for cell in w.index}\n",
    "    else:\n",
    "        pred = {cell: link(dm @ w.loc[cell][dmcols]) for cell in w.index}\n",
    "    # if type(nglm) == LinearGLM:\n",
    "    #     for cell in pred:\n",
    "    #         cellind = np.argwhere(nglm.clu_ids == cell)[0][0]\n",
    "    #         pred[cell] += np.mean(nglm.binnedspikes[:, cellind])\n",
    "    if not retlab:\n",
    "        return pred\n",
    "    else:\n",
    "        return pred, trlabels[trfilter].flatten()\n",
    "\n",
    "def pred_psth(nglm, align_time, t_before, t_after, targ_regressors=None, trials=None,\n",
    "              incl_bias=True):\n",
    "    if trials is None:\n",
    "        trials = nglm.design.trialsdf.index\n",
    "    times = nglm.design.trialsdf[align_time].apply(nglm.binf)\n",
    "    tbef_bin = nglm.binf(t_before)\n",
    "    taft_bin = nglm.binf(t_after)\n",
    "    pred, labels = predict(nglm, targ_regressors, trials, retlab=True, incl_bias=incl_bias)\n",
    "    t_inds = [np.searchsorted(labels, tr) + times[tr] for tr in trials]\n",
    "    winds = [(t - tbef_bin, t + taft_bin) for t in t_inds]\n",
    "    psths = {}\n",
    "    for cell in pred.keys():\n",
    "        cellpred = pred[cell]\n",
    "        windarr = np.vstack([cellpred[w[0]:w[1]] for w in winds])\n",
    "        psths[cell] = (np.mean(windarr, axis=0) / nglm.binwidth,\n",
    "                       np.std(windarr, axis=0) / nglm.binwidth)\n",
    "    return psths\n",
    "\n",
    "class GLMPredictor:\n",
    "    def __init__(self, nglm, spk_t, spk_clu, trialsdf, trial_ids):\n",
    "        self.covar = list(nglm.design.covar.keys())\n",
    "        self.nglm = nglm\n",
    "        self.binnedspikes = nglm.binnedspikes\n",
    "        self.design = nglm.design\n",
    "        self.spk_t = spk_t\n",
    "        self.spk_clu = spk_clu\n",
    "        self.trials = trial_ids#nglm.design.trialsdf.index\n",
    "        self.trialsdf = trialsdf#nglm.design.trialsdf #maybe not best way to do this\n",
    "        self.full_psths = {}\n",
    "        self.cov_psths = {}\n",
    "        self.combweights = nglm.combine_weights()\n",
    "\n",
    "    def psth_summary(self, align_time, unit, t_before=0.1, t_after=0.6, ax=None):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "        times = self.trialsdf.loc[self.trials, align_time] #\n",
    "        peri_event_time_histogram(self.spk_t, self.spk_clu,\n",
    "                                  times,\n",
    "                                  unit, t_before, t_after, bin_size=self.nglm.binwidth,\n",
    "                                  error_bars='sem', ax=ax[0], smoothing=0.0)\n",
    "        keytuple = (align_time, t_before, t_after)\n",
    "        if keytuple not in self.full_psths:\n",
    "            self.full_psths[keytuple] = pred_psth(self.nglm, align_time, t_before, t_after,\n",
    "                                                  trials=self.trials)\n",
    "            self.cov_psths[keytuple] = {}\n",
    "            tmp = self.cov_psths[keytuple]\n",
    "            for cov in self.covar:\n",
    "                tmp[cov] = pred_psth(self.nglm, align_time, t_before, t_after,\n",
    "                                     targ_regressors=[cov], trials=self.trials,\n",
    "                                     incl_bias=False)\n",
    "                ax[2].plot(self.combweights[cov].loc[unit])\n",
    "        x = np.arange(-t_before, t_after, self.nglm.binwidth) + 0.01\n",
    "        ax[0].plot(x, self.full_psths[keytuple][unit][0], label='Model prediction', color='r')\n",
    "        ax[0].legend()\n",
    "        for cov in self.covar:\n",
    "            ax[1].plot(x, self.cov_psths[keytuple][cov][unit][0], label=cov)\n",
    "        ax[1].set_title('Individual component contributions')\n",
    "        ax[1].legend()\n",
    "        if hasattr(self.nglm, 'clu_regions'):\n",
    "            unitregion = self.nglm.clu_regions[unit]\n",
    "            plt.suptitle(f'Unit {unit} from region {unitregion}')\n",
    "        else:\n",
    "            plt.suptitle(f'Unit {unit}')\n",
    "        plt.tight_layout()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_glm_lists = []\n",
    "for i, design in enumerate(design_list):\n",
    "    nglm = lm.LinearGLM(design, spk_times_list[i], clus_list[i], \n",
    "                        estimator=RidgeCV(cv=3), binwidth=binwidth)\n",
    "    nglm.fit(train_idx=train_trial_ids[i])\n",
    "    \n",
    "#     pred = GLMPredictor(nglm, spk_times_list[i], clus_list[i], trialsdf_list[i])\n",
    "#     for j, unit in enumerate(np.unique(clus_list[i])):\n",
    "#         ax = pred.psth_summary('firstMovement_times', unit, t_before=0.5, t_after=1.0)\n",
    "#         plt.show()\n",
    "        \n",
    "    fit_glm_lists.append(nglm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_score_list = []\n",
    "glm_leave_one_out = []\n",
    "glm_single_covariate = []\n",
    "glm_covs = fit_glm_lists[0].design.covar\n",
    "for i, nglm in enumerate(fit_glm_lists):\n",
    "    score = nglm.score(testinds=test_trial_ids[i])\n",
    "    test_score_list.append(score)\n",
    "    \n",
    "    trlabels = nglm.design.trlabels\n",
    "    train = np.isin(trlabels, train_trial_ids[i]).flatten()\n",
    "    test = np.isin(trlabels, test_trial_ids[i]).flatten()\n",
    "    \n",
    "    sfs = mut.SequentialSelector(nglm, train=train, test=test, direction='backward', \n",
    "                                 n_features_to_select=len(nglm.design.covar)-1)\n",
    "    sfs.fit(progress=True)\n",
    "    for clu in sfs.all_scores.index:\n",
    "        sfs.all_scores.loc[clu] = score.loc[clu] - sfs.all_scores.loc[clu]\n",
    "    glm_leave_one_out.append(sfs.all_scores)\n",
    "    \n",
    "    sfs = mut.SequentialSelector(nglm, train_trial_ids[i], test_trial_ids[i], direction='forward', \n",
    "                                 n_features_to_select=1)\n",
    "    sfs.fit(progress=True)\n",
    "    glm_single_covariate.append(sfs.all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_covs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(test_score_list)):\n",
    "    scores.append(test_score_list[i].loc[cluster_list[i]].to_numpy())\n",
    "scores = np.concatenate(scores)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(scores, scores)\n",
    "plt.axvline(np.median(scores))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_score_save_path = save_data_path(figure='figure9')\n",
    "np.save(glm_score_save_path.joinpath('glm_scores.npy'), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data from GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_cell(stimkerns, fdbkkerns, fmovekern, wheelkern, wheeltraces,\n",
    "                  stimtimes, fdbktimes, feedbacktypes, fmovetimes, priors, prev_priors, contrasts,\n",
    "                  wheelmoves, pgain=5.0, gain=15.0, num_trials=300, linear=True, ret_raw=False):\n",
    "\n",
    "    trialspikes = []\n",
    "    trialrates = []\n",
    "    trialwheel = []\n",
    "    if ret_raw:\n",
    "        trialcont = []\n",
    "    trialrange = range(num_trials)\n",
    "    zipiter = zip(trialrange, stimtimes, fdbktimes, fmovetimes, priors, prev_priors,\n",
    "                  contrasts, feedbacktypes, wheelmoves)\n",
    "    for i, start, end, fmove, prior, prev_prior, contrast, feedbacktype, wheelchoice in zipiter:\n",
    "        trial_len = int(1.5 / binwidth)\n",
    "        stimarr = np.zeros(trial_len)\n",
    "        fdbkarr = np.zeros(trial_len)\n",
    "        fmovekarr = np.zeros(trial_len)\n",
    "        stimarr[int(np.ceil(start / binwidth))] = 1\n",
    "        fdbkarr[int(np.ceil(end / binwidth))] = 1\n",
    "        fmovekarr[int(np.ceil(fmove / binwidth))] = 1\n",
    "        stimkern = stimkerns[0] if contrast > 0 else stimkerns[1]\n",
    "        fdbkkern = fdbkkerns[0] if feedbacktype == 1 else fdbkkerns[1]\n",
    "        stimarr = np.convolve(stimkern, stimarr)[:trial_len]\n",
    "        fdbkarr = np.convolve(fdbkkern, fdbkarr)[:trial_len]\n",
    "        fmovearr = np.convolve(fmovekern, fmovekarr)[:trial_len]\n",
    "        fdbkind = int(np.ceil(end / binwidth))\n",
    "\n",
    "        wheel = wheeltraces[wheelchoice].copy()\n",
    "        lendiff = trial_len - wheel.shape[0]\n",
    "        if lendiff >= 0:\n",
    "            wheel = np.pad(wheel, (0, lendiff), constant_values=0)\n",
    "        else:\n",
    "            wheel = wheel[:lendiff]\n",
    "        wheelinterp = interp1d(np.arange(len(wheel)) * binwidth,\n",
    "                               wheel, fill_value='extrapolate')\n",
    "        wheelnew = wheelinterp(np.arange(trial_len) * binwidth)\n",
    "        wheelarr = convbasis(wheelnew.reshape(-1, 1),\n",
    "                             wheelkern.reshape(-1, 1),\n",
    "                             offset=-np.ceil(0.3 / binwidth).astype(int)).flatten()\n",
    "        \n",
    "        priorarr = np.array([prev_prior] * fdbkind +\n",
    "                            [prior] * (trial_len - fdbkind))\n",
    "        priorarr = pgain * priorarr\n",
    "        kernsum = priorarr + stimarr + fdbkarr + fmovearr + wheelarr\n",
    "\n",
    "        if not linear:\n",
    "            ratevals = np.exp(kernsum + gain) * binwidth\n",
    "            spikecounts = np.random.poisson(ratevals)\n",
    "        else:\n",
    "            ratevals = (kernsum + gain) * binwidth\n",
    "            contspikecounts = np.random.normal(\n",
    "                loc=ratevals, scale=gain * binwidth)\n",
    "            spikecounts = np.round(contspikecounts).astype(int)\n",
    "        if ret_raw:\n",
    "            trialcont.append(contspikecounts)\n",
    "        spike_times = []\n",
    "\n",
    "        noisevals = uniform(low=0, high=binwidth - 1e-8,\n",
    "                            size=np.max(spikecounts))\n",
    "        for i in np.nonzero(spikecounts)[0]:\n",
    "            curr_t = i * binwidth\n",
    "            for j in range(spikecounts[i]):\n",
    "                jitterspike = curr_t + noisevals[j]\n",
    "                if jitterspike < 0:\n",
    "                    jitterspike = 0\n",
    "                spike_times.append(jitterspike)\n",
    "        trialspikes.append(spike_times)\n",
    "        trialrates.append(ratevals)\n",
    "        trialwheel.append(wheel)\n",
    "    retlist = [trialspikes, contrasts, priors, stimtimes,\n",
    "               fdbktimes, fmovetimes, feedbacktypes, trialwheel, trialrates,\n",
    "               trialcont if ret_raw else None]\n",
    "    return retlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_simcell_data(trialspikes, contrasts, priors, stimtimes, fdbktimes, fmovetimes, feedbacktypes,\n",
    "                        trialwheel):\n",
    "    trialsdf = pd.DataFrame()\n",
    "    trialends = np.cumsum(fmovetimes + 1.0)\n",
    "    trialends = np.pad(trialends, (1,0), constant_values=0)\n",
    "    cat_stimtimes = np.array(\n",
    "        [trialends[i] + st for i, st in enumerate(stimtimes)])\n",
    "    cat_fdbktimes = np.array(\n",
    "        [trialends[i] + ft for i, ft in enumerate(fdbktimes)])\n",
    "    cat_fmovetimes = np.array(\n",
    "        [trialends[i] + fmt for i, fmt in enumerate(fmovetimes)])\n",
    "    contrastLeft = np.empty_like(contrasts)\n",
    "    contrastRight = np.empty_like(contrasts)\n",
    "    contrastLeft[:] = np.NaN\n",
    "    contrastRight[:] = np.NaN\n",
    "    \n",
    "    contrastLeft[np.where(contrasts>0)] = contrasts[np.where(contrasts>0)]\n",
    "    contrastRight[np.where(contrasts<0)] = contrasts[np.where(contrasts<0)]\n",
    "    \n",
    "    trialsdf['contrastLeft'] = contrastLeft\n",
    "    trialsdf['contrastRight'] = contrastRight\n",
    "    trialsdf['prior'] = priors\n",
    "    trialsdf['prior_last'] = np.pad(priors[1:], (0, 1), constant_values=0)\n",
    "    trialsdf['trial_start'] = trialends[:-1]\n",
    "    trialsdf['trial_end'] = trialends[1:]\n",
    "    trialsdf['stimOn_times'] = cat_stimtimes\n",
    "    trialsdf['feedback_times'] = cat_fdbktimes\n",
    "    trialsdf['firstMovement_times'] = cat_fmovetimes\n",
    "    trialsdf['feedbackType'] = feedbacktypes\n",
    "    trialsdf['wheel_velocity'] = trialwheel\n",
    "\n",
    "    indices = trialsdf.index\n",
    "    adj_spkt = np.hstack([trialsdf.loc[i].trial_start + np.array(t)\n",
    "                          for i, t in zip(indices, trialspikes)])\n",
    "    return np.sort(adj_spkt), trialsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mtnn_form(trialsdf, trial_len=30, nfeats=8, binwidth=0.05):\n",
    "    feature = np.zeros((len(trialsdf), trial_len, nfeats+1))\n",
    "    for i in range(len(trialsdf)):\n",
    "        stimon_bin = (trialsdf.loc[i]['stimOn_times']-trialsdf.loc[i]['trial_start'])/binwidth\n",
    "        stimon_bin = np.floor(stimon_bin).astype(int)\n",
    "        \n",
    "        feedback_bin = (trialsdf.loc[i]['feedback_times']-trialsdf.loc[i]['trial_start'])/binwidth\n",
    "        feedback_bin = np.floor(feedback_bin).astype(int)\n",
    "        \n",
    "        fmv_bin = (trialsdf.loc[i]['firstMovement_times']-trialsdf.loc[i]['trial_start'])/binwidth\n",
    "        fmv_bin = np.floor(fmv_bin).astype(int)\n",
    "        \n",
    "        if np.isnan(trialsdf.loc[i]['contrastRight']):\n",
    "            feature[i,stimon_bin,1] = np.abs(trialsdf.loc[i]['contrastLeft'])\n",
    "        else:\n",
    "            feature[i,stimon_bin,2] = np.abs(trialsdf.loc[i]['contrastRight'])\n",
    "            \n",
    "        if trialsdf.loc[i]['feedbackType'] == -1:\n",
    "            feature[i,feedback_bin,3] = 1\n",
    "        else:\n",
    "            feature[i,feedback_bin,4] = 1\n",
    "        \n",
    "        feature[i,fmv_bin,5] = 1\n",
    "        \n",
    "        feature[i,:,6] = trialsdf.loc[i]['prior']\n",
    "        feature[i,:,7] = trialsdf.loc[i]['prior_last']\n",
    "        feature[i,:,8] = trialsdf.loc[i]['wheel_velocity']\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials=350\n",
    "n_test = int(num_trials*0.2)\n",
    "n_train = int((num_trials-n_test)*0.8)\n",
    "n_val = num_trials - n_train - n_test\n",
    "\n",
    "test_idx = np.random.choice(np.arange(num_trials), size=n_test, replace=False)\n",
    "test_bool = np.zeros(num_trials).astype(bool)\n",
    "test_bool[test_idx] = True\n",
    "\n",
    "train_idx = np.random.choice(np.arange(num_trials)[~test_bool], size=n_train, replace=False)\n",
    "train_bool = np.zeros(num_trials).astype(bool)\n",
    "train_bool[train_idx] = True\n",
    "\n",
    "val_bool = np.zeros(num_trials).astype(bool)\n",
    "val_bool[~np.logical_or(test_bool, train_bool)] = True\n",
    "\n",
    "train_idx = np.arange(num_trials)[train_bool]\n",
    "val_idx = np.arange(num_trials)[val_bool]\n",
    "test_idx = np.arange(num_trials)[test_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=0b01101001 + 0b01100010 + 0b01101100)\n",
    "\n",
    "fdb_rt_vals = np.linspace(0.1, 0.7, num=10)\n",
    "fdb_rt_probs = np.array([0.15970962, 0.50635209, 0.18693285, 0.0707804, 0.02540835,\n",
    "                     0.01633394, 0.00907441, 0.00725953, 0.00544465, 0.01270417])\n",
    "\n",
    "stim_rt_vals = np.linspace(0.25, 0.4, num=10)\n",
    "stim_rt_probs = np.array([0.1324877, 0.10914096, 0.03974338, 0.05596731, 0.14581747, 0.08437234,\n",
    "                     0.01841735, 0.15889255, 0.16163811, 0.09352284])\n",
    "\n",
    "contrastvals = [0.0625, 0.125, 0.25, 1.] + [-0.0625, -0.125, -0.25, -1.]\n",
    "\n",
    "unit_id = 0\n",
    "mtnn_feature_list = []\n",
    "mtnn_output_list = []\n",
    "\n",
    "simulated_feature_list = []\n",
    "simulated_output_list = []\n",
    "simulated_glm_leave_one_out = []\n",
    "simulated_glm_scores = []\n",
    "\n",
    "scales_dict = {}\n",
    "\n",
    "for i, eid in notebook.tqdm(enumerate(mtnn_eids)):\n",
    "    print('processing session {}'.format(eid))\n",
    "    \n",
    "    trialsdf = trialsdf_list[i]\n",
    "    nglm = fit_glm_lists[i]\n",
    "    clus = cluster_list[i]\n",
    "    weights = nglm.combine_weights()\n",
    "\n",
    "    wheeltraces = trialsdf.wheel_velocity.to_list()\n",
    "    firstMovement_times = np.ones(num_trials) * 0.5\n",
    "    stimtimes = rng.choice(stim_rt_vals, size=num_trials, p=stim_rt_probs) \\\n",
    "        + normal(size=num_trials) * 0.05\n",
    "    fdbktimes = rng.choice(fdb_rt_vals, size=num_trials, p=fdb_rt_probs) \\\n",
    "        + firstMovement_times + normal(size=num_trials) * 0.05\n",
    "    if prior_list[i].shape[0] < num_trials:\n",
    "        priors = np.concatenate((prior_list[i], prior_list[i][:num_trials-prior_list[i].shape[0]]))\n",
    "    else:\n",
    "        priors = prior_list[i][:num_trials]\n",
    "    prev_priors = np.pad(priors, (1,0), constant_values=0)[:-1]\n",
    "    contrasts = rng.choice(contrastvals, replace=True, size=num_trials)\n",
    "    feedbacktypes = rng.choice([-1, 1], size=num_trials, p=[0.1, 0.9])\n",
    "    wheelmoves = rng.choice(np.arange(len(wheeltraces)), size=num_trials)\n",
    "    \n",
    "    session_simulated_spkidx_list = []\n",
    "    session_simulated_feature_list = []\n",
    "    \n",
    "    print(f'total number of units: {len(clus)}')\n",
    "    \n",
    "    for j, clu in notebook.tqdm(enumerate(clus)):\n",
    "        \n",
    "        scales = np.random.uniform(1, 2, size=6)\n",
    "        scales_dict[(eid,clu)] = scales\n",
    "        \n",
    "        stimkernL = weights['stimonL'].loc[clu].to_numpy() * (1/binwidth) * scales[0]\n",
    "        stimkernR = weights['stimonR'].loc[clu].to_numpy() * (1/binwidth) * scales[1]\n",
    "        fdbkkern1 = weights['correct'].loc[clu].to_numpy() * (1/binwidth) * scales[2]\n",
    "        fdbkkern2 = weights['incorrect'].loc[clu].to_numpy() * (1/binwidth) * scales[3]\n",
    "        wheelkern = weights['wheel'].loc[clu].to_numpy() * (1/binwidth) * scales[4]\n",
    "        fmovekern = weights['fmove'].loc[clu].to_numpy() * (1/binwidth) * scales[5]\n",
    "    \n",
    "        ret = simulate_cell((stimkernL,stimkernR), (fdbkkern1,fdbkkern2), \n",
    "                            fmovekern, wheelkern, \n",
    "                            wheeltraces,\n",
    "                            stimtimes, fdbktimes, feedbacktypes, firstMovement_times,\n",
    "                            priors, prev_priors, contrasts,\n",
    "                            wheelmoves, pgain=2.0, gain=8.0, \n",
    "                            num_trials=num_trials, linear=True, ret_raw=False)\n",
    "        trialspikes, contrasts, priors, stimtimes, fdbktimes, fmovetimes, feedbacktypes, trialwheel = ret[:-2]\n",
    "        adj_spkt, new_trialsdf = concat_simcell_data(trialspikes, contrasts, priors, \n",
    "                                                 stimtimes, fdbktimes, fmovetimes,\n",
    "                                                 feedbacktypes, trialwheel)\n",
    "        sess_clu = np.ones_like(adj_spkt, dtype=int) * unit_id\n",
    "        \n",
    "        if j == 0:\n",
    "            design = generate_design(new_trialsdf.copy(), priors, 0.4, bases, \n",
    "                                     prior_last=prev_priors, binwidth=binwidth)\n",
    "            feature = to_mtnn_form(new_trialsdf)\n",
    "        feature = feature.copy()\n",
    "        feature[:,:,0] = unit_id\n",
    "        session_simulated_feature_list.append(feature[None])\n",
    "            \n",
    "        nglm = lm.LinearGLM(design, adj_spkt, sess_clu, \n",
    "                        estimator=RidgeCV(cv=3), binwidth=binwidth)\n",
    "        nglm.fit(train_idx=train_idx)\n",
    "        \n",
    "#         pred = GLMPredictor(nglm, adj_spkt, sess_clu, new_trialsdf, np.arange(num_trials))\n",
    "#         for j, unit in enumerate(np.unique(sess_clu)):\n",
    "#             ax = pred.psth_summary('firstMovement_times', unit, t_before=0.5, t_after=1.0)\n",
    "#             plt.show()\n",
    "        \n",
    "        score = nglm.score()\n",
    "        simulated_glm_scores.append(score)\n",
    "\n",
    "        sfs = mut.SequentialSelector(nglm, train_idx, test_idx, direction='backward', \n",
    "                                     n_features_to_select=len(nglm.design.covar)-1)\n",
    "        sfs.fit(progress=True)\n",
    "        sfs.all_scores.loc[unit_id] = score.loc[unit_id] - sfs.all_scores.loc[unit_id]\n",
    "        simulated_glm_leave_one_out.append(sfs.all_scores)\n",
    "#         plt.bar(glm_covs.keys(), sfs.all_scores.loc[unit_id].to_numpy())\n",
    "#         plt.show()\n",
    "\n",
    "        unit_id += 1\n",
    "        \n",
    "        nbins = int(1.5/binwidth)\n",
    "        raster = np.zeros((len(new_trialsdf), nbins))\n",
    "        for trial in range(len(new_trialsdf)):\n",
    "            for n in range(nbins):\n",
    "                idx = np.logical_and(adj_spkt>=1.5*trial+binwidth*n, adj_spkt<1.5*trial+binwidth*(n+1))\n",
    "                raster[trial,n] = idx.astype(int).sum() / binwidth\n",
    "                \n",
    "        plt.figure(figsize=(8,2))\n",
    "        plt.plot(raster.mean(0), color='k')\n",
    "        plt.show()\n",
    "                \n",
    "        session_simulated_spkidx_list.append(raster[None])\n",
    "    simulated_output_list.append(np.concatenate(session_simulated_spkidx_list, axis=0))\n",
    "    simulated_feature_list.append(np.concatenate(session_simulated_feature_list, axis=0))\n",
    "simulated_glm_leave_one_out = pd.concat(simulated_glm_leave_one_out)\n",
    "simulated_glm_scores = pd.concat(simulated_glm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = []\n",
    "feature_concat = []\n",
    "for i in notebook.tqdm(range(len(simulated_feature_list))):\n",
    "    shape_list.append(simulated_feature_list[i].shape)\n",
    "    feature_concat.append(simulated_feature_list[i].reshape((-1,)+simulated_feature_list[i].shape[-2:]))\n",
    "feature_concat = np.concatenate(feature_concat)\n",
    "print('feature_concat shape: {}'.format(feature_concat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheel_min = feature_concat[:,:,8].min()\n",
    "wheel_max = feature_concat[:,:,8].max()\n",
    "feature_concat[:,:,8] = -1 + 2*(feature_concat[:,:,8] - wheel_min) / (wheel_max - wheel_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_feature_list = []\n",
    "idx = 0\n",
    "for sh in shape_list:\n",
    "    n = sh[0]*sh[1]\n",
    "    preprocessed_feature_list.append(feature_concat[idx:idx+n].reshape(sh))\n",
    "    idx += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape_list = []\n",
    "val_shape_list = []\n",
    "test_shape_list = []\n",
    "\n",
    "train_bool_list = []\n",
    "val_bool_list = []\n",
    "test_bool_list = []\n",
    "\n",
    "train_trial_list = []\n",
    "val_trial_list = []\n",
    "test_trial_list = []\n",
    "\n",
    "train_feature = []\n",
    "val_feature = []\n",
    "test_feature = []\n",
    "\n",
    "train_output = []\n",
    "val_output = []\n",
    "test_output = []\n",
    "\n",
    "for i in notebook.tqdm(range(len(preprocessed_feature_list))):\n",
    "    \n",
    "    sh = shape_list[i]\n",
    "    \n",
    "    train_shape_list.append((sh[0],n_train,)+sh[-2:])\n",
    "    val_shape_list.append((sh[0],n_val,)+sh[-2:])\n",
    "    test_shape_list.append((sh[0],n_test,)+sh[-2:])\n",
    "    \n",
    "    train_bool_list.append(train_bool)\n",
    "    val_bool_list.append(val_bool)\n",
    "    test_bool_list.append(test_bool)\n",
    "    \n",
    "    train_trial_list.append(train_idx)\n",
    "    val_trial_list.append(val_idx)\n",
    "    test_trial_list.append(test_idx)\n",
    "    \n",
    "    train_feature.append(preprocessed_feature_list[i][:,train_bool].reshape((-1,)+sh[-2:]))\n",
    "    val_feature.append(preprocessed_feature_list[i][:,val_bool].reshape((-1,)+sh[-2:]))\n",
    "    test_feature.append(preprocessed_feature_list[i][:,test_bool].reshape((-1,)+sh[-2:]))\n",
    "    \n",
    "    train_output.append(simulated_output_list[i][:,train_bool].reshape(-1, sh[-2]))\n",
    "    val_output.append(simulated_output_list[i][:,val_bool].reshape(-1, sh[-2]))\n",
    "    test_output.append(simulated_output_list[i][:,test_bool].reshape(-1, sh[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_data_path(figure='figure10').joinpath('simulated_data')\n",
    "save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "save_path_train = save_data_path(figure='figure10').joinpath('simulated_data/train')\n",
    "save_path_train.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "save_path_val = save_data_path(figure='figure10').joinpath('simulated_data/validation')\n",
    "save_path_val.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "save_path_test = save_data_path(figure='figure10').joinpath('simulated_data/test')\n",
    "save_path_test.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path_train.joinpath('shape.npy'), np.asarray(train_shape_list))\n",
    "np.save(save_path_val.joinpath('shape.npy'), np.asarray(val_shape_list))\n",
    "np.save(save_path_test.joinpath('shape.npy'), np.asarray(test_shape_list))\n",
    "\n",
    "np.save(save_path_train.joinpath('bool.npy'), np.asarray(train_bool_list, dtype=object))\n",
    "np.save(save_path_val.joinpath('bool.npy'), np.asarray(val_bool_list, dtype=object))\n",
    "np.save(save_path_test.joinpath('bool.npy'), np.asarray(test_bool_list, dtype=object))\n",
    "\n",
    "np.save(save_path_train.joinpath('trials.npy'), np.asarray(train_trial_list, dtype=object))\n",
    "np.save(save_path_val.joinpath('trials.npy'), np.asarray(val_trial_list, dtype=object))\n",
    "np.save(save_path_test.joinpath('trials.npy'), np.asarray(test_trial_list, dtype=object))\n",
    "\n",
    "np.save(save_path_train.joinpath('feature.npy'), np.concatenate(train_feature))\n",
    "np.save(save_path_val.joinpath('feature.npy'), np.concatenate(val_feature))\n",
    "np.save(save_path_test.joinpath('feature.npy'), np.concatenate(test_feature))\n",
    "\n",
    "np.save(save_path_train.joinpath('output.npy'), np.concatenate(train_output))\n",
    "np.save(save_path_val.joinpath('feature.npy'), np.concatenate(val_output))\n",
    "np.save(save_path_test.joinpath('feature.npy'), np.concatenate(test_output))\n",
    "\n",
    "np.save(save_path.joinpath('glm_scores.npy'), simulated_glm_scores)\n",
    "np.save(save_path.joinpath('glm_leave_one_out.npy'), simulated_glm_leave_one_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv_resubmit",
   "language": "python",
   "name": "iblenv_resubmit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
